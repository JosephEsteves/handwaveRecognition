{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d17467-d455-4567-857f-7f28169e1b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Converting Keras model to INT8 TFLite...\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\josep\\AppData\\Local\\Temp\\tmpd19s6dmb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\josep\\AppData\\Local\\Temp\\tmpd19s6dmb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\josep\\AppData\\Local\\Temp\\tmpd19s6dmb'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 7), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2162780670608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780676592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780683984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780850128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780679408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780681696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780854880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780852944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780850832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780857344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780855056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780854176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780859456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780860160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780853824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780864208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780862272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780862800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780862976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780933808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780935216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780936272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780933984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780933104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780941024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780940496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780938384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780944720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780942080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780941552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780943312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2162780982960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\anaconda3\\envs\\ai_projects-env\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved quantized model to: Keras/C1gesture_Epoch90.keras.keras.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\anaconda3\\envs\\ai_projects-env\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INT8 Handwave detector running... Press Q to quit.\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  1\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  2\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  3\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  4\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  5\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  6\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  7\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  8\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  9\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  10\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  11\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  12\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  13\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  14\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  15\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  16\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  17\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_3', 'angle_6']) → Hello World!  18\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  19\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  20\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  21\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  22\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  23\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  24\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  25\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  26\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  27\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  28\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  29\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_2', 'angle_4']) → Hello World!  30\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_2', 'angle_4']) → Hello World!  31\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  32\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  33\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  34\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  35\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  36\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  37\n",
      "🖐️ Handwave Detected! (Detected angles: ['angle_1', 'angle_4', 'angle_6']) → Hello World!  38\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "keras_model_path = \"Keras/C1gesture_Epoch90.keras\"\n",
    "tflite_model_path = \"Keras/C1gesture_Epoch90.keras.keras.tflite\"\n",
    "frame_window = 10\n",
    "image_size = (128, 128)\n",
    "angle_labels = [f\"angle_{i}\" for i in range(1, 7)]\n",
    "no_wave_label = \"noWave\"\n",
    "all_labels = angle_labels + [no_wave_label]\n",
    "\n",
    "# === Step 1: Convert to INT8 TFLite (if not already exists) ===\n",
    "if not os.path.exists(tflite_model_path):\n",
    "    print(\"🔁 Converting Keras model to INT8 TFLite...\")\n",
    "\n",
    "    # Load Keras model\n",
    "    model = tf.keras.models.load_model(keras_model_path)\n",
    "\n",
    "    # Define representative dataset\n",
    "    def representative_data_gen():\n",
    "        for _ in range(100):\n",
    "            dummy_img = np.random.rand(*image_size, 3).astype(np.float32)\n",
    "            dummy_img = np.expand_dims(dummy_img, axis=0)\n",
    "            yield [dummy_img]\n",
    "\n",
    "    # Convert to int8 TFLite\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "\n",
    "    tflite_model = converter.convert()\n",
    "    with open(tflite_model_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "    print(f\"✅ Saved quantized model to: {tflite_model_path}\")\n",
    "else:\n",
    "    print(f\"📦 Found existing quantized model: {tflite_model_path}\")\n",
    "\n",
    "# === Step 2: Load TFLite model ===\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# === Step 3: Set up camera and prediction history ===\n",
    "pred_history = deque(maxlen=frame_window)\n",
    "cap = cv2.VideoCapture(0)\n",
    "i = 0\n",
    "\n",
    "print(\"🚀 INT8 Handwave detector running... Press Q to quit.\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # === Preprocess frame ===\n",
    "    resized = cv2.resize(frame, image_size)\n",
    "    input_scale, input_zero_point = input_details[0]['quantization']\n",
    "    input_tensor = resized.astype(np.float32) / 255.0\n",
    "    input_tensor = input_tensor / input_scale + input_zero_point\n",
    "    input_tensor = np.clip(input_tensor, 0, 255).astype(np.uint8)\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "    # === TFLite Inference ===\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    pred_label = all_labels[np.argmax(output)]\n",
    "    pred_history.append(pred_label)\n",
    "\n",
    "    # === Display prediction on video ===\n",
    "    cv2.putText(frame, f\"Prediction: {pred_label}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Live Handwave Detector (INT8 TFLite)', frame)\n",
    "\n",
    "    # === Detect handwave ===\n",
    "    unique_angles = set(label for label in pred_history if label in angle_labels)\n",
    "    if len(unique_angles) >= 3:\n",
    "        i += 1\n",
    "        print(f\"🖐️ Handwave Detected! (Detected angles: {sorted(unique_angles)}) → Hello World! \", i)\n",
    "        pred_history.clear()\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30984bd5-4fea-456c-929e-05d0e151d219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
