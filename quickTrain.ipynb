{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56591b7b-d7db-4424-afb2-671edc9f8074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 490 images belonging to 7 classes.\n",
      "{'angle_1': 0, 'angle_2': 1, 'angle_3': 2, 'angle_4': 3, 'angle_5': 4, 'angle_6': 5, 'noWave': 6}\n",
      "ğŸ“Š Final class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0}\n",
      "Found 105 images belonging to 7 classes.\n",
      "Found 105 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\anaconda3\\envs\\ai_projects-env\\lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\josep\\anaconda3\\envs\\ai_projects-env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.4066 - loss: 1.7247\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65714, saving model to Keras/gesture_Best.keras\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 148ms/step - accuracy: 0.4069 - loss: 1.7234 - val_accuracy: 0.6571 - val_loss: 1.3391\n",
      "Epoch 2/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5184 - loss: 1.3679\n",
      "Epoch 2: val_accuracy improved from 0.65714 to 0.68571, saving model to Keras/gesture_Best.keras\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 147ms/step - accuracy: 0.5183 - loss: 1.3680 - val_accuracy: 0.6857 - val_loss: 0.7655\n",
      "Epoch 3/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.5272 - loss: 1.2825\n",
      "Epoch 3: val_accuracy did not improve from 0.68571\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 142ms/step - accuracy: 0.5269 - loss: 1.2835 - val_accuracy: 0.0667 - val_loss: 36.9386\n",
      "Epoch 4/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2543 - loss: 2.1884\n",
      "Epoch 4: val_accuracy did not improve from 0.68571\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 139ms/step - accuracy: 0.2546 - loss: 2.1872 - val_accuracy: 0.2762 - val_loss: 30.4305\n",
      "Epoch 5/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.4404 - loss: 1.4058\n",
      "Epoch 5: val_accuracy improved from 0.68571 to 0.92381, saving model to Keras/gesture_Best.keras\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 148ms/step - accuracy: 0.4406 - loss: 1.4056 - val_accuracy: 0.9238 - val_loss: 0.9404\n",
      "Epoch 6/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5384 - loss: 1.2230\n",
      "Epoch 6: val_accuracy did not improve from 0.92381\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 145ms/step - accuracy: 0.5385 - loss: 1.2229 - val_accuracy: 0.4857 - val_loss: 19.0749\n",
      "Epoch 7/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6032 - loss: 1.1862\n",
      "Epoch 7: val_accuracy did not improve from 0.92381\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 147ms/step - accuracy: 0.6032 - loss: 1.1860 - val_accuracy: 0.1429 - val_loss: 360.8118\n",
      "Epoch 8/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.3182 - loss: 1.8938\n",
      "Epoch 8: val_accuracy did not improve from 0.92381\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 142ms/step - accuracy: 0.3184 - loss: 1.8933 - val_accuracy: 0.8476 - val_loss: 0.6888\n",
      "Epoch 9/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.5856 - loss: 1.2377\n",
      "Epoch 9: val_accuracy did not improve from 0.92381\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 137ms/step - accuracy: 0.5856 - loss: 1.2377 - val_accuracy: 0.8857 - val_loss: 0.2901\n",
      "Epoch 10/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6235 - loss: 1.1126\n",
      "Epoch 10: val_accuracy improved from 0.92381 to 0.96190, saving model to Keras/gesture_Best.keras\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 140ms/step - accuracy: 0.6235 - loss: 1.1127 - val_accuracy: 0.9619 - val_loss: 0.1208\n",
      "Epoch 11/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.6343 - loss: 1.0369\n",
      "Epoch 11: val_accuracy improved from 0.96190 to 0.97143, saving model to Keras/gesture_Best.keras\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 139ms/step - accuracy: 0.6343 - loss: 1.0369 - val_accuracy: 0.9714 - val_loss: 0.1009\n",
      "Epoch 12/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7413 - loss: 0.8448\n",
      "Epoch 12: val_accuracy improved from 0.97143 to 0.98095, saving model to Keras/gesture_Best.keras\n",
      "\n",
      "ğŸ“¦ Saved model at epoch 12 (Training Accuracy: 0.7388) â†’ gesture_70acc.keras\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 143ms/step - accuracy: 0.7413 - loss: 0.8449 - val_accuracy: 0.9810 - val_loss: 0.0553\n",
      "Epoch 13/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7727 - loss: 0.8317\n",
      "Epoch 13: val_accuracy did not improve from 0.98095\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 141ms/step - accuracy: 0.7727 - loss: 0.8317 - val_accuracy: 0.9810 - val_loss: 0.0464\n",
      "Epoch 14/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7974 - loss: 0.8125\n",
      "Epoch 14: val_accuracy improved from 0.98095 to 0.99048, saving model to Keras/gesture_Best.keras\n",
      "\n",
      "ğŸ“¦ Saved model at epoch 14 (Training Accuracy: 0.8041) â†’ gesture_80acc.keras\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 144ms/step - accuracy: 0.7974 - loss: 0.8123 - val_accuracy: 0.9905 - val_loss: 0.0349\n",
      "Epoch 15/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.8039 - loss: 0.6724\n",
      "Epoch 15: val_accuracy did not improve from 0.99048\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 142ms/step - accuracy: 0.8039 - loss: 0.6725 - val_accuracy: 0.9524 - val_loss: 2.0846\n",
      "Epoch 16/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.8013 - loss: 0.6865\n",
      "Epoch 16: val_accuracy did not improve from 0.99048\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 136ms/step - accuracy: 0.8013 - loss: 0.6866 - val_accuracy: 0.9143 - val_loss: 0.4194\n",
      "Epoch 17/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.8054 - loss: 0.7303\n",
      "Epoch 17: val_accuracy did not improve from 0.99048\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 137ms/step - accuracy: 0.8055 - loss: 0.7301 - val_accuracy: 0.9714 - val_loss: 0.0578\n",
      "Epoch 18/18\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.8403 - loss: 0.6569\n",
      "Epoch 18: val_accuracy did not improve from 0.99048\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 141ms/step - accuracy: 0.8404 - loss: 0.6566 - val_accuracy: 0.9810 - val_loss: 0.0437\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0123\n",
      "\n",
      "ğŸ“Š Final Test Accuracy: 0.9619\n",
      "âœ… Model saved as gesture_CNN.keras\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "import os                                              \n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# === Settings ===\n",
    "image_size = (128, 128)\n",
    "batch_size = 2\n",
    "epochs = 18\n",
    "num_classes = 7\n",
    "dataset_dir = \"theDataset\"\n",
    "\n",
    "# === Load datasets ===\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "val_datagen   = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, \"Train\"),\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"  # since you're using softmax and 7 classes\n",
    ")\n",
    "\n",
    "print(train_gen.class_indices)\n",
    "# {'angle_1': 0, 'angle_2': 1, ..., 'angle_6': 5, 'noWave': 6}\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# === Step 1: Compute class counts\n",
    "counter = Counter(train_gen.classes)\n",
    "total = sum(counter.values())\n",
    "\n",
    "# === Step 2: Initial inverse-frequency weighting\n",
    "class_weight = {i: total / (len(counter) * count) for i, count in counter.items()}\n",
    "\n",
    "# === Step 3: Boost wave classes\n",
    "wave_boost_factor = 1.0\n",
    "wave_class_indices = [0, 1, 2, 3, 4, 5]  # angle_1 to angle_6\n",
    "for i in wave_class_indices:\n",
    "    class_weight[i] *= wave_boost_factor\n",
    "\n",
    "print(\"ğŸ“Š Final class weights:\", class_weight)\n",
    "\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, \"Validation\"),\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, \"Test\"),\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False  # keep test order stable\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FullDatasetPredictionLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_gen, val_gen, test_gen, log_dir=\"PredictionLogs\"):\n",
    "        super().__init__()\n",
    "        self.train_gen = train_gen\n",
    "        self.val_gen = val_gen\n",
    "        self.test_gen = test_gen\n",
    "        self.log_dir = log_dir\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "        self.logs = {\n",
    "            \"Train\": [],\n",
    "            \"Validation\": [],\n",
    "            \"Test\": []\n",
    "        }\n",
    "\n",
    "    def _log_predictions_for_dataset(self, dataset_name, generator, epoch):\n",
    "        # Predict for the entire dataset\n",
    "        probs = self.model.predict(generator, verbose=0)\n",
    "        true_labels = np.argmax(np.vstack([generator[i][1] for i in range(len(generator))]), axis=1)\n",
    "\n",
    "        self.logs[dataset_name].append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"predictions\": [\n",
    "                {\n",
    "                    \"true_label\": int(true_labels[i]),\n",
    "                    \"probs\": probs[i].tolist()\n",
    "                }\n",
    "                for i in range(len(probs))\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        # Save to disk\n",
    "        with open(os.path.join(self.log_dir, f\"{dataset_name}_predictions.json\"), 'w') as f:\n",
    "            json.dump(self.logs[dataset_name], f, indent=2)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self._log_predictions_for_dataset(\"Train\", self.train_gen, epoch)\n",
    "        self._log_predictions_for_dataset(\"Validation\", self.val_gen, epoch)\n",
    "        self._log_predictions_for_dataset(\"Test\", self.test_gen, epoch)\n",
    "\n",
    "     \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=[128,128,3]), \n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), \n",
    "    tf.keras.layers.BatchNormalization(),          \n",
    "    tf.keras.layers.MaxPooling2D((2,2)),            \n",
    "    tf.keras.layers.Dropout(0.2),                    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(128, activation = 'relu',  kernel_initializer='he_uniform'), \n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Dropout(0.5), \n",
    "    tf.keras.layers.Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Compile the model ===\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "\n",
    "es = EarlyStopping(monitor = \"val_accuracy\", min_delta = 0.01, patience = 10, verbose = 1)\n",
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, save_freq):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.save_freq = save_freq\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.save_freq == 0:  # Save on specific iterations (1-indexed)\n",
    "            self.model.save(self.filepath.format(epoch=epoch + 1))\n",
    "\n",
    "model_cp = ModelCheckpoint(filepath = 'Keras/gesture_Best.keras', monitor = \"val_accuracy\",\n",
    "                           save_best_only = True,\n",
    "                           save_weights_only = False,\n",
    "                           verbose = 1)\n",
    "# Define your custom checkpoint for specific iterations\n",
    "specific_iteration_cp = CustomModelCheckpoint(filepath='Keras/gesture_Epoch{epoch:02d}.keras',\n",
    "                                              save_freq=18)  \n",
    "\n",
    "class HistorySaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, file_path):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.history = []\n",
    "        self.last_epoch = 0\n",
    "\n",
    "        # Load existing history if file exists\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                self.history = data.get('history', [])\n",
    "                self.last_epoch = data.get('last_epoch', 0)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Append current epoch metrics\n",
    "        self.history.append({**logs, 'epoch': epoch + 1})  # 1-indexed epoch\n",
    "\n",
    "        # Save updated history\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump({\n",
    "                'history': self.history,\n",
    "                'last_epoch': epoch + 1\n",
    "            }, file, indent=4)\n",
    "\n",
    "\n",
    "class SaveHistoryAnd90Acc(Callback):\n",
    "    def __init__(self, history_path='training_history.json', save_path='gesture_90acc.keras', acc_threshold=0.90):\n",
    "        super().__init__()\n",
    "        self.history_path = history_path\n",
    "        self.save_path = save_path\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.history = []\n",
    "        self.last_epoch = 0\n",
    "        self.saved = False  # Tracks if model was already saved at threshold\n",
    "\n",
    "        # Load existing history if it exists\n",
    "        if os.path.exists(self.history_path):\n",
    "            with open(self.history_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                self.history = data.get('history', [])\n",
    "                self.last_epoch = data.get('last_epoch', 0)\n",
    "                \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Save training history\n",
    "        self.history.append({**logs, 'epoch': epoch + 1})\n",
    "        with open(self.history_path, 'w') as file:\n",
    "            json.dump({\n",
    "                'history': self.history,\n",
    "                'last_epoch': epoch + 1\n",
    "            }, file, indent=4)\n",
    "\n",
    "        # Check for 90% training accuracy\n",
    "        acc = logs.get('accuracy')\n",
    "        if acc is not None and not self.saved and acc >= self.acc_threshold:\n",
    "            self.model.save(self.save_path)\n",
    "            print(f\"\\nğŸ“¦ Saved model at epoch {epoch+1} (Training Accuracy: {acc:.4f}) â†’ {self.save_path}\")\n",
    "            self.saved = True\n",
    "                \n",
    "\n",
    "class SaveHistoryAnd80Acc(Callback):\n",
    "    def __init__(self, history_path='training_history.json', save_path='gesture_80acc.keras', acc_threshold=0.80):\n",
    "        super().__init__()\n",
    "        self.history_path = history_path\n",
    "        self.save_path = save_path\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.history = []\n",
    "        self.last_epoch = 0\n",
    "        self.saved = False  # Tracks if model was already saved at threshold\n",
    "\n",
    "        # Load existing history if it exists\n",
    "        if os.path.exists(self.history_path):\n",
    "            with open(self.history_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                self.history = data.get('history', [])\n",
    "                self.last_epoch = data.get('last_epoch', 0)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Save training history\n",
    "        self.history.append({**logs, 'epoch': epoch + 1})\n",
    "        with open(self.history_path, 'w') as file:\n",
    "            json.dump({\n",
    "                'history': self.history,\n",
    "                'last_epoch': epoch + 1\n",
    "            }, file, indent=4)\n",
    "\n",
    "        # Check for 80% training accuracy\n",
    "        acc = logs.get('accuracy')\n",
    "        if acc is not None and not self.saved and acc >= self.acc_threshold:\n",
    "            self.model.save(self.save_path)\n",
    "            print(f\"\\nğŸ“¦ Saved model at epoch {epoch+1} (Training Accuracy: {acc:.4f}) â†’ {self.save_path}\")\n",
    "            self.saved = True\n",
    "class SaveHistoryAnd80Acc(Callback):\n",
    "    def __init__(self, history_path='training_history.json', save_path='gesture_80acc.keras', acc_threshold=0.80):\n",
    "        super().__init__()\n",
    "        self.history_path = history_path\n",
    "        self.save_path = save_path\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.history = []\n",
    "        self.last_epoch = 0\n",
    "        self.saved = False  # Tracks if model was already saved at threshold\n",
    "\n",
    "        # Load existing history if it exists\n",
    "        if os.path.exists(self.history_path):\n",
    "            with open(self.history_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                self.history = data.get('history', [])\n",
    "                self.last_epoch = data.get('last_epoch', 0)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Save training history\n",
    "        self.history.append({**logs, 'epoch': epoch + 1})\n",
    "        with open(self.history_path, 'w') as file:\n",
    "            json.dump({\n",
    "                'history': self.history,\n",
    "                'last_epoch': epoch + 1\n",
    "            }, file, indent=4)\n",
    "\n",
    "        # Check for 80% training accuracy\n",
    "        acc = logs.get('accuracy')\n",
    "        if acc is not None and not self.saved and acc >= self.acc_threshold:\n",
    "            self.model.save(self.save_path)\n",
    "            print(f\"\\nğŸ“¦ Saved model at epoch {epoch+1} (Training Accuracy: {acc:.4f}) â†’ {self.save_path}\")\n",
    "            self.saved = True\n",
    "class SaveHistoryAnd70Acc(Callback):\n",
    "    def __init__(self, history_path='training_history.json', save_path='gesture_70acc.keras', acc_threshold=0.70):\n",
    "        super().__init__()\n",
    "        self.history_path = history_path\n",
    "        self.save_path = save_path\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.history = []\n",
    "        self.last_epoch = 0\n",
    "        self.saved = False  # Tracks if model was already saved at threshold\n",
    "\n",
    "        # Load existing history if it exists\n",
    "        if os.path.exists(self.history_path):\n",
    "            with open(self.history_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                self.history = data.get('history', [])\n",
    "                self.last_epoch = data.get('last_epoch', 0)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Save training history\n",
    "        self.history.append({**logs, 'epoch': epoch + 1})\n",
    "        with open(self.history_path, 'w') as file:\n",
    "            json.dump({\n",
    "                'history': self.history,\n",
    "                'last_epoch': epoch + 1\n",
    "            }, file, indent=4)\n",
    "\n",
    "        # Check for 70% training accuracy\n",
    "        acc = logs.get('accuracy')\n",
    "        if acc is not None and not self.saved and acc >= self.acc_threshold:\n",
    "            self.model.save(self.save_path)\n",
    "            print(f\"\\nğŸ“¦ Saved model at epoch {epoch+1} (Training Accuracy: {acc:.4f}) â†’ {self.save_path}\")\n",
    "            self.saved = True\n",
    "\n",
    "combined_callback = SaveHistoryAnd90Acc(\n",
    "    history_path='trainingHistory.json',\n",
    "    save_path='gesture_90acc.keras',\n",
    "    acc_threshold=0.90\n",
    ")\n",
    "\n",
    "combined_callback1 = SaveHistoryAnd80Acc(\n",
    "    history_path='trainingHistory.json',\n",
    "    save_path='gesture_80acc.keras',\n",
    "    acc_threshold=0.80\n",
    ")\n",
    "\n",
    "combined_callback2 = SaveHistoryAnd80Acc(\n",
    "    history_path='trainingHistory.json',\n",
    "    save_path='gesture_70acc.keras',\n",
    "    acc_threshold=0.70\n",
    ")\n",
    "# Usage\n",
    "file_path = 'trainingHistory.json'\n",
    "history_saver = HistorySaver(file_path)\n",
    "# Load the last completed epoch to start from there\n",
    "start_epoch = history_saver.last_epoch\n",
    "\n",
    "prediction_logger = FullDatasetPredictionLogger(train_gen, val_gen, test_gen)\n",
    "callbacks = [model_cp, specific_iteration_cp, history_saver, combined_callback,combined_callback1,combined_callback2]\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=epochs,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Train the model ===\n",
    "#history = model.fit(train_gen,callbacks = [model_cp, specific_iteration_cp],validation_data=val_gen,epochs=epochs,class_weight=class_weight, verbose=1)\n",
    "\n",
    "# === Evaluate on test set ===\n",
    "test_loss, test_acc = model.evaluate(test_gen, verbose=1)\n",
    "print(f\"\\nğŸ“Š Final Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# === Save model ===\n",
    "model.save(\"gesture_CNN.keras\")\n",
    "print(\"âœ… Model saved as gesture_CNN.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1d142c-7590-405a-8589-dae725b636f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Subfolders found in Train/:\n",
      "['angle_1', 'angle_2', 'angle_3', 'angle_4', 'angle_5', 'angle_6', 'noWave']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_dir = \"theDataset/Train\"\n",
    "print(\"ğŸ” Subfolders found in Train/:\")\n",
    "print(os.listdir(train_dir))\n",
    "#checks to see if you have hidden subfolders in your folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3ac597-eeb4-4a76-9291-49021cbfb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"theDataset/Train/.ipynb_checkpoints\", ignore_errors=True)\n",
    "shutil.rmtree(\"theDataset/Validation/.ipynb_checkpoints\", ignore_errors=True)\n",
    "shutil.rmtree(\"theDataset/Test/.ipynb_checkpoints\", ignore_errors=True)\n",
    "#If you get errors when trying process your datasets run this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913b6dd8-e787-4ad7-8b10-91349b5ea089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,736</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m896\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m9,248\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚          \u001b[38;5;34m18,496\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚          \u001b[38;5;34m36,928\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚       \u001b[38;5;34m8,388,736\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚             \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   â”‚             \u001b[38;5;34m903\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,368,183</span> (96.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,368,183\u001b[0m (96.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,455,847</span> (32.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,455,847\u001b[0m (32.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,911,696</span> (64.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,911,696\u001b[0m (64.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f96c05-1675-4782-8fdd-73c3c440d698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv2d\n",
      "1 batch_normalization\n",
      "2 conv2d_1\n",
      "3 batch_normalization_1\n",
      "4 max_pooling2d\n",
      "5 dropout\n",
      "6 conv2d_2\n",
      "7 batch_normalization_2\n",
      "8 conv2d_3\n",
      "9 batch_normalization_3\n",
      "10 max_pooling2d_1\n",
      "11 dropout_1\n",
      "12 flatten\n",
      "13 dense\n",
      "14 batch_normalization_4\n",
      "15 dropout_2\n",
      "16 dense_1\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fff62-92c3-442e-9c8a-b91bf23c9928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
